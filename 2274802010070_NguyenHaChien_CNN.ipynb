{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Câu 1: Thay đổi số lượng epoch\n",
        "- **Yêu cầu**: Tăng số lượng epoch từ 5 lên 10 trong phần huấn luyện mô hình.\n",
        "- **Hướng dẫn**: Tìm dòng `for epoch in range(5):` và sửa thành `for epoch in range(10):`. Chạy lại code và ghi nhận:\n",
        "  - Độ chính xác trên tập test có thay đổi không? Nếu có, tăng hay giảm?\n",
        "  - Biểu đồ mất mát (loss) thay đổi thế nào qua 10 epoch? Có xu hướng nào đáng chú ý không (ví dụ: giảm đều, chững lại)?\n",
        "-  Viết ngắn gọn (2-3 câu) về lý do tại sao số epoch ảnh hưởng đến kết quả.\n",
        "\n",
        "### Câu 2: Thêm một tầng tích chập\n",
        "- **Yêu cầu**: Thêm một tầng tích chập thứ ba (`conv3`) vào mô hình `MNIST_CNN`.\n",
        "- **Hướng dẫn**:\n",
        "  - Trong hàm `__init__`, thêm `self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)` (32 kênh đầu vào từ `conv2`, 64 kênh đầu ra).\n",
        "  - Trong hàm `forward`, thêm `x = self.pool(torch.relu(self.conv3(x)))` sau dòng `x = self.pool(torch.relu(self.conv2(x)))`.\n",
        "  - Kích thước sau `conv3` và pooling sẽ là 64x1x1 (vì 5x5 -> 3x3 -> 1x1 sau hai lần pooling và tích chập). Sửa tầng `fc1` thành `self.fc1 = nn.Linear(64 * 1 * 1, 10)` và dòng `x.view(-1, 64 * 1 * 1)` tương ứng.\n",
        "  - Chạy lại code và ghi nhận độ chính xác mới trên tập test.\n",
        "- Viết ngắn gọn (2-3 câu) về tác dụng của việc thêm tầng tích chập (ví dụ: tìm đặc trưng phức tạp hơn, ảnh hưởng đến độ chính xác)."
      ],
      "metadata": {
        "id": "VC4a_nXTUG5U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhG4XVBjUAzm",
        "outputId": "93efe1cf-321b-43ed-9366-051565e1a5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 42.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.17MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.7MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.44MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2679\n",
            "Epoch 2, Loss: 0.0838\n",
            "Epoch 3, Loss: 0.0643\n",
            "Epoch 4, Loss: 0.0540\n",
            "Epoch 5, Loss: 0.0467\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.ToTensor()  # Chuyển ảnh thành tensor\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 2. Định nghĩa mô hình CNN\n",
        "class MNIST_CNN(nn.Module):  # Tạo lớp MNIST_CNN kế thừa từ nn.Module (lớp cơ bản của PyTorch)\n",
        "    def __init__(self):  # Hàm khởi tạo mô hình\n",
        "        super(MNIST_CNN, self).__init__()  # Gọi hàm khởi tạo của lớp cha (nn.Module)\n",
        "        # Tầng tích chập 1: 1 kênh đầu vào (ảnh đen trắng) -> 16 kênh đầu ra, filter 3x3\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)  # Tích chập giảm kích thước từ 28x28 -> 26x26\n",
        "        # Tầng tích chập 2: 16 kênh đầu vào -> 32 kênh đầu ra, filter 3x3\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)  # Tích chập giảm từ 12x12 -> 10x10 (sau pooling)\n",
        "        # Tầng pooling: vùng 2x2, giảm kích thước một nửa\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Ví dụ: 26x26 -> 13x13, 10x10 -> 5x5\n",
        "        # Tầng fully connected: từ 32 kênh * 5x5 (800) -> 10 lớp (0-9)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10)  # Duỗi feature map thành vector rồi phân loại\n",
        "\n",
        "    def forward(self, x):  # Hàm forward định nghĩa luồng dữ liệu qua các tầng\n",
        "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1 -> ReLU (loại giá trị âm) -> Pool (giảm kích thước)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool, cuối cùng ra 32x5x5\n",
        "        x = x.view(-1, 32 * 5 * 5)  # Duỗi tensor thành vector, -1 tự động tính batch size\n",
        "        x = self.fc1(x)  # Qua tầng fully connected, ra 10 giá trị (logits cho 0-9)\n",
        "        return x  # Trả về kết quả dự đoán\n",
        "# Khởi tạo mô hình\n",
        "model = MNIST_CNN()  # Tạo một instance của lớp MNIST_CNN\n",
        "criterion = nn.CrossEntropyLoss()  # Định nghĩa hàm mất mát CrossEntropy (dùng cho phân loại nhiều lớp)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Dùng SGD với learning rate 0.01 và momentum 0.9 để tối ưu\n",
        "\n",
        "\n",
        "# 3. Huấn luyện mô hình\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Chọn GPU nếu có, không thì dùng CPU\n",
        "model.to(device)  # Chuyển mô hình sang thiết bị đã chọn (GPU/CPU)\n",
        "\n",
        "loss_values = []  # Tạo list để lưu giá trị mất mát trung bình của mỗi epoch\n",
        "for epoch in range(5): # Lặp qua 5 epoch (mỗi epoch là một lần duyệt hết dữ liệu)\n",
        "    running_loss = 0.0  # Biến để cộng dồn mất mát trong epoch\n",
        "    for images, labels in train_loader:  # Lặp qua từng batch trong tập huấn luyện\n",
        "        images, labels = images.to(device), labels.to(device)  # Chuyển ảnh và nhãn sang GPU/CPU\n",
        "\n",
        "        optimizer.zero_grad()  # Xóa gradient cũ để tránh tích lũy từ bước trước\n",
        "        outputs = model(images)  # Đưa ảnh qua mô hình, nhận dự đoán (logits)\n",
        "        loss = criterion(outputs, labels)  # Tính mất mát giữa dự đoán và nhãn thật\n",
        "        loss.backward()  # Tính gradient ngược (backpropagation)\n",
        "        optimizer.step()  # Cập nhật trọng số dựa trên gradient\n",
        "\n",
        "        running_loss += loss.item()  # Cộng dồn giá trị mất mát của batch\n",
        "    epoch_loss = running_loss / len(train_loader)  # Tính mất mát trung bình của epoch\n",
        "    loss_values.append(epoch_loss)  # Lưu mất mát trung bình vào list\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")  # In mất mát trung bình sau mỗi epoch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.ToTensor()  # Chuyển ảnh thành tensor\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 2. Định nghĩa mô hình CNN\n",
        "class MNIST_CNN(nn.Module):  # Tạo lớp MNIST_CNN kế thừa từ nn.Module (lớp cơ bản của PyTorch)\n",
        "    def __init__(self):  # Hàm khởi tạo mô hình\n",
        "        super(MNIST_CNN, self).__init__()  # Gọi hàm khởi tạo của lớp cha (nn.Module)\n",
        "        # Tầng tích chập 1: 1 kênh đầu vào (ảnh đen trắng) -> 16 kênh đầu ra, filter 3x3\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)  # Tích chập giảm kích thước từ 28x28 -> 26x26\n",
        "        # Tầng tích chập 2: 16 kênh đầu vào -> 32 kênh đầu ra, filter 3x3\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)  # Tích chập giảm từ 12x12 -> 10x10 (sau pooling)\n",
        "        # Tầng pooling: vùng 2x2, giảm kích thước một nửa\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Ví dụ: 26x26 -> 13x13, 10x10 -> 5x5\n",
        "        # Tầng fully connected: từ 32 kênh * 5x5 (800) -> 10 lớp (0-9)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 10)  # Duỗi feature map thành vector rồi phân loại\n",
        "\n",
        "    def forward(self, x):  # Hàm forward định nghĩa luồng dữ liệu qua các tầng\n",
        "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1 -> ReLU (loại giá trị âm) -> Pool (giảm kích thước)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool, cuối cùng ra 32x5x5\n",
        "        x = x.view(-1, 32 * 5 * 5)  # Duỗi tensor thành vector, -1 tự động tính batch size\n",
        "        x = self.fc1(x)  # Qua tầng fully connected, ra 10 giá trị (logits cho 0-9)\n",
        "        return x  # Trả về kết quả dự đoán\n",
        "# Khởi tạo mô hình\n",
        "model = MNIST_CNN()  # Tạo một instance của lớp MNIST_CNN\n",
        "criterion = nn.CrossEntropyLoss()  # Định nghĩa hàm mất mát CrossEntropy (dùng cho phân loại nhiều lớp)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Dùng SGD với learning rate 0.01 và momentum 0.9 để tối ưu\n",
        "\n",
        "\n",
        "# 3. Huấn luyện mô hình\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Chọn GPU nếu có, không thì dùng CPU\n",
        "model.to(device)  # Chuyển mô hình sang thiết bị đã chọn (GPU/CPU)\n",
        "\n",
        "loss_values = []  # Tạo list để lưu giá trị mất mát trung bình của mỗi epoch\n",
        "for epoch in range(10): # Lặp qua 5 epoch (mỗi epoch là một lần duyệt hết dữ liệu)\n",
        "    running_loss = 0.0  # Biến để cộng dồn mất mát trong epoch\n",
        "    for images, labels in train_loader:  # Lặp qua từng batch trong tập huấn luyện\n",
        "        images, labels = images.to(device), labels.to(device)  # Chuyển ảnh và nhãn sang GPU/CPU\n",
        "\n",
        "        optimizer.zero_grad()  # Xóa gradient cũ để tránh tích lũy từ bước trước\n",
        "        outputs = model(images)  # Đưa ảnh qua mô hình, nhận dự đoán (logits)\n",
        "        loss = criterion(outputs, labels)  # Tính mất mát giữa dự đoán và nhãn thật\n",
        "        loss.backward()  # Tính gradient ngược (backpropagation)\n",
        "        optimizer.step()  # Cập nhật trọng số dựa trên gradient\n",
        "\n",
        "        running_loss += loss.item()  # Cộng dồn giá trị mất mát của batch\n",
        "    epoch_loss = running_loss / len(train_loader)  # Tính mất mát trung bình của epoch\n",
        "    loss_values.append(epoch_loss)  # Lưu mất mát trung bình vào list\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")  # In mất mát trung bình sau mỗi epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AhsPyhMWohC",
        "outputId": "2becdc54-c24a-4e32-e01c-40926f9ea6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3060\n",
            "Epoch 2, Loss: 0.0826\n",
            "Epoch 3, Loss: 0.0638\n",
            "Epoch 4, Loss: 0.0514\n",
            "Epoch 5, Loss: 0.0467\n",
            "Epoch 6, Loss: 0.0404\n",
            "Epoch 7, Loss: 0.0377\n",
            "Epoch 8, Loss: 0.0344\n",
            "Epoch 9, Loss: 0.0317\n",
            "Epoch 10, Loss: 0.0300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu 1.\n",
        "Biểu đồ mất mát này giảm chậm dần đều qua mỗi epoch\n",
        "Lý do tại sao số epoch ảnh hưởng bởi vì: Gía trị epoch càng cao thì Độ mất mát giảm xuống --> Xác định được độ chính xác một cách dễ dàng"
      ],
      "metadata": {
        "id": "07dIl3tOX6RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.ToTensor()  # Chuyển ảnh thành tensor\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 2. Định nghĩa mô hình CNN\n",
        "class MNIST_CNN(nn.Module):  # Tạo lớp MNIST_CNN kế thừa từ nn.Module (lớp cơ bản của PyTorch)\n",
        "    def __init__(self):  # Hàm khởi tạo mô hình\n",
        "        super(MNIST_CNN, self).__init__()  # Gọi hàm khởi tạo của lớp cha (nn.Module)\n",
        "        # Tầng tích chập 1: 1 kênh đầu vào (ảnh đen trắng) -> 16 kênh đầu ra, filter 3x3\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)  # Tích chập giảm kích thước từ 28x28 -> 26x26\n",
        "        # Tầng tích chập 2: 16 kênh đầu vào -> 32 kênh đầu ra, filter 3x3\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)  # Tích chập giảm từ 12x12 -> 10x10 (sau pooling)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
        "        # Tầng pooling: vùng 2x2, giảm kích thước một nửa\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Ví dụ: 26x26 -> 13x13, 10x10 -> 5x5\n",
        "        # Tầng fully connected: từ 32 kênh * 5x5 (800) -> 10 lớp (0-9)\n",
        "        self.fc1 = nn.Linear(64 * 1 * 1, 10)  # Duỗi feature map thành vector rồi phân loại\n",
        "\n",
        "    def forward(self, x):  # Hàm forward định nghĩa luồng dữ liệu qua các tầng\n",
        "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1 -> ReLU (loại giá trị âm) -> Pool (giảm kích thước)\n",
        "        x = self.pool(torch.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool, cuối cùng ra 32x5x5\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 1 * 1)  # Duỗi tensor thành vector, -1 tự động tính batch size\n",
        "        x = self.fc1(x)  # Qua tầng fully connected, ra 10 giá trị (logits cho 0-9)\n",
        "        return x  # Trả về kết quả dự đoán\n",
        "# Khởi tạo mô hình\n",
        "model = MNIST_CNN()  # Tạo một instance của lớp MNIST_CNN\n",
        "criterion = nn.CrossEntropyLoss()  # Định nghĩa hàm mất mát CrossEntropy (dùng cho phân loại nhiều lớp)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Dùng SGD với learning rate 0.01 và momentum 0.9 để tối ưu\n",
        "\n",
        "\n",
        "# 3. Huấn luyện mô hình\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Chọn GPU nếu có, không thì dùng CPU\n",
        "model.to(device)  # Chuyển mô hình sang thiết bị đã chọn (GPU/CPU)\n",
        "\n",
        "loss_values = []  # Tạo list để lưu giá trị mất mát trung bình của mỗi epoch\n",
        "for epoch in range(5): # Lặp qua 5 epoch (mỗi epoch là một lần duyệt hết dữ liệu)\n",
        "    running_loss = 0.0  # Biến để cộng dồn mất mát trong epoch\n",
        "    for images, labels in train_loader:  # Lặp qua từng batch trong tập huấn luyện\n",
        "        images, labels = images.to(device), labels.to(device)  # Chuyển ảnh và nhãn sang GPU/CPU\n",
        "\n",
        "        optimizer.zero_grad()  # Xóa gradient cũ để tránh tích lũy từ bước trước\n",
        "        outputs = model(images)  # Đưa ảnh qua mô hình, nhận dự đoán (logits)\n",
        "        loss = criterion(outputs, labels)  # Tính mất mát giữa dự đoán và nhãn thật\n",
        "        loss.backward()  # Tính gradient ngược (backpropagation)\n",
        "        optimizer.step()  # Cập nhật trọng số dựa trên gradient\n",
        "\n",
        "        running_loss += loss.item()  # Cộng dồn giá trị mất mát của batch\n",
        "    epoch_loss = running_loss / len(train_loader)  # Tính mất mát trung bình của epoch\n",
        "    loss_values.append(epoch_loss)  # Lưu mất mát trung bình vào list\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")  # In mất mát trung bình sau mỗi epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBZIjnjNfeBK",
        "outputId": "c98a1e70-8229-41cb-dffd-84556a8543cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4650\n",
            "Epoch 2, Loss: 0.1157\n",
            "Epoch 3, Loss: 0.0880\n",
            "Epoch 4, Loss: 0.0682\n",
            "Epoch 5, Loss: 0.0588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tác dụng của việc thêm tầng tích chập đó là làm giảm tốc độ mất của dữ liệu, để cho nó dễ dàng tiếp cận hơn"
      ],
      "metadata": {
        "id": "FyrQcoaThtd2"
      }
    }
  ]
}